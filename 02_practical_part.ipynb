{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical example using an Exhaust gas temperature simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary setup for Google Colab & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ml-kiwi-com/ml-prague.git\n",
    "! pip install -r ml-prague/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ml-prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.numerical_simulator as simulator\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import  ConstantKernel, RBF\n",
    "from src import plots\n",
    "from src import utils\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated variable: **Maximal exhaust gas temperature during take off of an airplane. [K]**\n",
    "\n",
    "Input variables:\n",
    "\n",
    "| name | description | unit |\n",
    "| --- | --- | --- |\n",
    "| *oat* | Outside air temperature at take off | [K] |\n",
    "| *max_speed* | Maximal flight speed at take off | [km/h] |\n",
    "| *altitude* | Airport altitude at take off | [m] |\n",
    "| *humidity* | Air humidity at take off | [%] |\n",
    "| *air_density* | Air density at take off | [kg/m3] |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = 200\n",
    "egt_threshold = 1250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's generate a dataframe of input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = simulator.generate_input_data(num_sim)\n",
    "X.sample(5).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use our complex and heavy simulator to generate the true values of the target variable\n",
    "Note the potential simulation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = simulator.simulate_max_egt(X)\n",
    "print(f\"Output range is [{round(y.min(),2)} ; {round(y.max(), 2)}]\")\n",
    "y.sample(5).rename('egt').to_frame().round(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's identify dangerous observations where temperature is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_risk_obs = (y > egt_threshold).sum()\n",
    "print(f\"Number of obs that are potentially dangerous: {nbr_risk_obs} out of {num_sim}\\n\")\n",
    "rng_max = y.argmax()\n",
    "x_max = X.loc[rng_max,]\n",
    "print(\"The worst observation of all:\")\n",
    "x_max.round(2).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk = X[y > egt_threshold]\n",
    "print(\"Only oat and air_density are influential on the risk area.\")\n",
    "X_risk.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gaussian Process Regression\n",
    "First we need to scale the input data before applying the Kriging algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_test = 10000\n",
    "X_test = utils.generate_input_data(num_sim_test)\n",
    "y_test = utils.simulate_max_egt(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a grid on which we will be building the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_1D = np.linspace(0, 1, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D]*5))).T.reshape(-1, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build and fit the Kriging model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "    np.repeat(1.0, X.shape[1]), length_scale_bounds=(0.1, 1e4)\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True\n",
    ")\n",
    "gaussian_process.fit(X_scaled, y)\n",
    "gaussian_process.kernel_.get_params()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained GPR, we can now predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, y_std = gaussian_process.predict(X_scaled, return_std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the Kriging estimators.\n",
    "\n",
    "We create 1D slices of the 5D space. For each slice, we select one observation at which we keep 4 dimensions constant.\n",
    "We then inspect what will happen to our target's prediction if we change the values of the remaining dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "vis_index = rng.choice(X_scaled.shape[0], size=1, replace=False)\n",
    "x_predict = X_scaled[vis_index, :]\n",
    "y_predict = y[vis_index]\n",
    "x_axis = np.linspace(-2, 2, 101)\n",
    "plots.show_multiD_slices_plots(X, x_predict, x_axis, gaussian_process, y_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = 100\n",
    "y_test_pred = gaussian_process.predict(X_test_scaled)\n",
    "mse_test = (((y_test - y_test_pred)/y_range)**2)\n",
    "mae_test = abs(y_test - y_test_pred)/y_range\n",
    "\n",
    "rmse_rounded = round(np.mean(mse_test) ** 0.5 * 100, 2)\n",
    "mae_rounded = round(np.mean(mae_test) * 100, 2)\n",
    "print(f\"Leave-one-out error metrics: \\n\"\n",
    "      f\"    RMSE: {rmse_rounded}% \\n\"\n",
    "      f\"    MAE:  {mae_rounded}%.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Approach\n",
    "\n",
    "As every observation is precious, we do not want to throw away any, which means that we cannot do a standard train-test set approach.\n",
    "\n",
    "First let's generate some simulations, scale them, and build the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = 50\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "print(f\"Design space dimensions: {X.shape}\")\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "grid_1D = np.linspace(0, 1, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D] * 5))).T.reshape(-1, 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Kriging model, train it, and store hyperparameters for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "    np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e4)\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True\n",
    ")\n",
    "gaussian_process.fit(X_scaled, y)\n",
    "\n",
    "k1_LOO, k2_LOO = (\n",
    "    gaussian_process.kernel_.k1.constant_value,\n",
    "    gaussian_process.kernel_.k2.length_scale,\n",
    ")\n",
    "kernel_LOO = ConstantKernel(k1_LOO, constant_value_bounds=\"fixed\") * RBF(\n",
    "    length_scale=k2_LOO, length_scale_bounds=\"fixed\"\n",
    ")\n",
    "gaussian_process_LOO = GaussianProcessRegressor(kernel=kernel_LOO, optimizer=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the collection of LOO train/test and build Kriging model in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.split(X_scaled, y)\n",
    "y_pred_list = []\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "     X_train = X_scaled[train_index]\n",
    "     X_test = X_scaled[test_index]\n",
    "     y_train = y[train_index]\n",
    "     y_test = y[test_index]\n",
    "     gaussian_process_LOO.fit(X_train, y_train)\n",
    "     y_test_pred = gaussian_process_LOO.predict(X_test, return_std=False)\n",
    "     y_pred_list.append(y_test_pred[0])\n",
    "     mse_list.append(((y_test - y_test_pred) / y_test)  ** 2)\n",
    "     mae_list.append(abs((y_test - y_test_pred) / y_test))\n",
    "\n",
    "rmse_rounded = round(np.mean(mse_list) ** 0.5 * 100, 2)\n",
    "mae_rounded = round(np.mean(mae_list) * 100, 2)\n",
    "print(f\"Leave-one-out error metrics: \\n\"\n",
    "      f\"    relative RMSE: {rmse_rounded}% \\n\"\n",
    "      f\"    relative MAE:  {mae_rounded}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design - Local Improvement\n",
    "\n",
    "Generate inputs, scale data, make their copy for enrichment, generate grid.\n",
    "\n",
    "Generate test data (larger set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = 100\n",
    "num_sim = 30\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_rich = X_scaled.copy()\n",
    "y_rich = y.copy()\n",
    "\n",
    "num_sim_test = 10000\n",
    "X_test = utils.generate_input_data(num_sim_test)\n",
    "y_test = utils.simulate_max_egt(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "grid_1D = np.linspace(-2, 2, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D] * 5))).T.reshape(-1, X.shape[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate loop to add points to the design sequentially\n",
    "IMPORTANT: do not recalculate the hyperparameters after each added point but only after each added batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nbr = 6\n",
    "batch_size = 5\n",
    "for iter_batch in range(batch_nbr):\n",
    "    # Build Kriging model - estimate hyperparameters for the whole batch\n",
    "    if iter_batch == 0:\n",
    "        kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(np.repeat(1.0, X.shape[1]),\n",
    "                                                                           length_scale_bounds=(1, 1e6))\n",
    "    # In case a gpr has already be fitted, re-use last hyperparameters as initial steps for upcoming fitting\n",
    "    else:\n",
    "        kernel = ConstantKernel(k1_batch, constant_value_bounds=(1, 1e6)) * RBF(k2_batch,\n",
    "                                                                           length_scale_bounds=(1, 1e6))\n",
    "\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel,\n",
    "                                                random_state=0, n_restarts_optimizer=5, normalize_y=True)\n",
    "    gaussian_process.fit(X_rich, y_rich)\n",
    "\n",
    "    # Save resulting hyperparameters to fasten the model build in upcoming batch of points\n",
    "    k1_batch, k2_batch = gaussian_process.kernel_.k1.constant_value, gaussian_process.kernel_.k2.length_scale\n",
    "    kernel_batch = ConstantKernel(k1_batch, constant_value_bounds=\"fixed\") * RBF(length_scale=k2_batch,\n",
    "                                                                             length_scale_bounds=\"fixed\")\n",
    "    gaussian_process_batch = GaussianProcessRegressor(kernel=kernel_batch, optimizer=None)\n",
    "    gaussian_process_batch.fit(X_rich, y_rich)\n",
    "    kriging_mean, kriging_std = gaussian_process_batch.predict(X_grid_scaled, return_std=True)\n",
    "\n",
    "    # add \"batch_size\" points according to prediction with the same Kriging hyperparameters\n",
    "    for iter in range(batch_size):\n",
    "        # Pick point with highest Kriging error and add it to the design\n",
    "        rng_max = kriging_std.argmax()\n",
    "        new_x = X_grid_scaled[rng_max]\n",
    "        new_x_unscaled = scaler.inverse_transform(new_x.reshape(1, 5))\n",
    "        new_y = utils.simulate_max_egt(pd.DataFrame(new_x_unscaled, columns=X.columns))\n",
    "        X_rich = np.append(X_rich, [new_x], axis=0)\n",
    "        y_rich = np.append(y_rich, new_y)\n",
    "\n",
    "        # Re-run Kriging model w/ enriched design\n",
    "        gaussian_process_batch.fit(X_rich, y_rich)\n",
    "        kriging_mean, kriging_std = gaussian_process_batch.predict(X_grid_scaled, return_std=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design - EGO\n",
    "\n",
    "First, let's setup the data, scale the data and make copy for enrichment. Build grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGT_threshold = 1250\n",
    "\n",
    "num_sim = 30\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "print(f\"Design space dimensions: {X.shape}\")\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_rich = X_scaled.copy()\n",
    "y_rich = y.copy()\n",
    "\n",
    "grid_1D = np.linspace(-2, 2, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D] * 5))).T.reshape(-1, X.shape[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set te current maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_max_x = X_rich[y_rich.argmax()]\n",
    "current_max = y_rich.max()\n",
    "\n",
    "print(f\"Current max is y={current_max} for X:\")\n",
    "current_max_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Kriging model, estimate hyperparameters, improve maximum sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 20\n",
    "\n",
    "for iter in range(n_iter):\n",
    "    if iter == 0:\n",
    "        kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "            np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e6)\n",
    "        )\n",
    "    else:\n",
    "        kernel = ConstantKernel(k1, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "            k2, length_scale_bounds=(1, 1e6)\n",
    "        )\n",
    "    gaussian_process = GaussianProcessRegressor(\n",
    "        kernel=kernel, random_state=0, n_restarts_optimizer=20, normalize_y=True\n",
    "    )\n",
    "    gaussian_process.fit(X_rich, y_rich)\n",
    "    mean_prediction, std_prediction = gaussian_process.predict(X_grid_scaled, return_std=True)\n",
    "\n",
    "    k1, k2 = (\n",
    "        gaussian_process.kernel_.k1.constant_value,\n",
    "        gaussian_process.kernel_.k2.length_scale,\n",
    "    )\n",
    "\n",
    "    ei_x = utils.expected_improvement(mean_prediction, std_prediction, current_max)\n",
    "    rng_max_ei = ei_x.argmax()\n",
    "    new_x = X_grid_scaled[rng_max_ei]\n",
    "    new_x_unscaled = scaler.inverse_transform(new_x.reshape(1, 5))\n",
    "    new_y = utils.simulate_max_egt(pd.DataFrame(new_x_unscaled, columns=X.columns))\n",
    "    X_rich = np.append(X_rich, [new_x], axis=0)\n",
    "    y_rich = np.append(y_rich, new_y)\n",
    "\n",
    "    current_max_x = X_rich[y_rich.argmax()]\n",
    "    current_max = y_rich.max()\n",
    "\n",
    "print(f\"Final maximum: \\n\" f\"    X: {current_max_x}% \\n\" f\"    y:  {current_max}%.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buld Kriging model for the whole batch and check all observations that are above the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "    np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e6)\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True\n",
    ")\n",
    "gaussian_process.fit(X_rich, y_rich)\n",
    "mean_prediction, std_prediction = gaussian_process.predict(X_grid_scaled, return_std=True)\n",
    "\n",
    "bad_X_pred = pd.DataFrame(X_grid_scaled[mean_prediction > EGT_threshold], columns=X.columns)\n",
    "\n",
    "indices_bad_prob = (1 - norm.cdf((EGT_threshold - mean_prediction) / std_prediction)) > 0.2\n",
    "bad_X_prob = pd.DataFrame(X_grid_scaled[indices_bad_prob], columns=X.columns)\n",
    "\n",
    "display(bad_X_pred.describe())\n",
    "display(bad_X_prob.describe())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to the theoretical part\n",
    "\n",
    "https://colab.research.google.com/github/ml-kiwi-com/ml-prague/blob/main/01_theoretical_part.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
